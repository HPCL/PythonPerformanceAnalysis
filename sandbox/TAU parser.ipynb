{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import csv\n",
    "import glob\n",
    "import mmap\n",
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ElementTree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as st\n",
    "\n",
    "from sys import stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TAU trial data for TAU Profile.x.y.z format profiles\n",
    "Parses a set of TAU profile files and yields multi-indexed Pandas dataframes for the\n",
    "interval and atomic events.\n",
    "\"\"\"\n",
    "\n",
    "class TauProfileParser(object):\n",
    "    \"\"\"Parser for TAU's profile.* format.\"\"\"\n",
    "\n",
    "    _interval_header_re = re.compile(b'(\\\\d+) templated_functions_MULTI_(.+)')\n",
    "\n",
    "    _atomic_header_re = re.compile(b'(\\\\d+) userevents')\n",
    "\n",
    "    def __init__(self, trial, metric, metadata, indices, interval_data, atomic_events):\n",
    "        self.trial = trial\n",
    "        self.metric = metric\n",
    "        self.metadata = metadata\n",
    "        self.indices = indices\n",
    "        self._interval_data = interval_data\n",
    "        self._atomic_data = atomic_events\n",
    "\n",
    "    def interval_data(self):\n",
    "        return self._interval_data\n",
    "\n",
    "    def atomic_data(self):\n",
    "        return self._atomic_data\n",
    "\n",
    "    def get_value_types(self):\n",
    "        return [key for key in dict(self._interval_data.dtypes)\n",
    "                if dict(self._interval_data.dtypes)[key] in ['float64', 'int64']]\n",
    "\n",
    "    def summarize_samples(self, across_threads=False, callpaths=True):\n",
    "        groups = 'Timer Name' if across_threads else ['Node', 'Context', 'Thread', 'Timer Name']\n",
    "        if callpaths:\n",
    "            base_data = self._interval_data.loc[self._interval_data['Group'].str.contains(\"TAU_SAMPLE\")]\n",
    "        else:\n",
    "            base_data = self._interval_data.loc[self._interval_data['Timer Type'] == 'SAMPLE']\n",
    "        summary = base_data.groupby(groups).sum()\n",
    "        summary.index = summary.index.map(\n",
    "            lambda x: '[SUMMARY] ' + x if across_threads else (x[0], x[1], x[2], '[SUMMARY] ' + x[3]))\n",
    "        return summary\n",
    "\n",
    "    def summarize_allocations(self):\n",
    "        sums = self.atomic_data().groupby('Timer').agg({'Count': 'sum', 'Mean': 'mean'})\n",
    "        allocs = sums[sums.index.to_series().str.contains('alloc')][['Count', 'Mean']]\n",
    "        allocs['Total'] = allocs['Count'] * allocs['Mean']\n",
    "        return allocs\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_header(cls, fin):\n",
    "        match = cls._interval_header_re.match(fin.readline())\n",
    "        interval_count, metric = match.groups()\n",
    "        return int(interval_count), metric\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_metadata(cls, fin):\n",
    "        fields, xml_wanabe = fin.readline().split(b'<metadata>')\n",
    "        xml_wanabe = b'<metadata>' + xml_wanabe\n",
    "        if (fields != b\"# Name Calls Subrs Excl Incl ProfileCalls\" and\n",
    "                    fields != b'# Name Calls Subrs Excl Incl ProfileCalls # '):\n",
    "            raise RuntimeError('Invalid profile file: %s' % fin.name)\n",
    "        try:\n",
    "            metadata_tree = ElementTree.fromstring(xml_wanabe)\n",
    "        except ElementTree.ParseError as err:\n",
    "            raise RuntimeError('Invalid profile file: %s' % err)\n",
    "        metadata = {}\n",
    "        for attribute in metadata_tree.iter('attribute'):\n",
    "            name = attribute.find('name').text\n",
    "            value = attribute.find('value').text\n",
    "            metadata[name] = value\n",
    "        return metadata\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_interval_data(cls, fin, count):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_atomic_header(cls, fin):\n",
    "        aggregates = fin.readline().split(b' aggregates')[0]\n",
    "        if aggregates != b'0':\n",
    "            print(\"aggregates != 0, is '%s'\" % aggregates, file=stderr)\n",
    "        match = cls._atomic_header_re.match(fin.readline())\n",
    "        try:\n",
    "            count = int(match.group(1))\n",
    "            if fin.readline() != b\"# eventname numevents max min mean sumsqr\\n\":\n",
    "                raise RuntimeError('Invalid profile file: %s' % fin.name)\n",
    "        except AttributeError:\n",
    "            count = 0\n",
    "        return count\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_from_timer_name(name):\n",
    "        import re\n",
    "        tag_search = re.search('^\\[(\\w+)\\]\\s+(.*)', name)\n",
    "        timer_type, rest = tag_search.groups() if tag_search else (None, name)\n",
    "        name_search = re.search('(.+)\\[({.*)\\]', rest)\n",
    "        func_name, location = name_search.groups() if name_search else (rest, None)\n",
    "        return func_name, location, timer_type\n",
    "\n",
    "    @classmethod\n",
    "    def parse(cls, dir_path, filenames=None, trial=None):\n",
    "        if not os.path.isdir(dir_path):\n",
    "            print(\"Error: %s is not a directory.\" % dir_path, file=stderr)\n",
    "            sys.exit(1)\n",
    "        intervals = []\n",
    "        atomics = []\n",
    "        indices = []\n",
    "        trial_data_metric = None\n",
    "        trial_data_metadata = None\n",
    "        if filenames is None:\n",
    "            filenames = [os.path.basename(x) for x in glob.glob(os.path.join(dir_path, 'profile.*'))]\n",
    "        if not filenames:\n",
    "            print(\"Error: No profile files found.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        for filename in sorted(filenames,\n",
    "                               key=lambda s: [int(t) if t.isdigit() else t.lower() for t in re.split('(\\d+)', s)]):\n",
    "            location = os.path.basename(filename).replace('profile.', '')\n",
    "            node, context, thread = (int(x) for x in location.split('.'))\n",
    "            file_path = os.path.join(dir_path, filename)\n",
    "            # print(file_path)\n",
    "            with open(file_path) as fin:\n",
    "                mm = mmap.mmap(fin.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "                # mm = mmap.mmap(fin.fileno(), 0, mmap.MAP_PRIVATE, mmap.PROT_READ)\n",
    "                interval_count, metric = cls._parse_header(mm)\n",
    "                if not trial_data_metric:\n",
    "                    trial_data_metric = metric\n",
    "                metadata = cls._parse_metadata(mm)\n",
    "                if not trial_data_metadata:\n",
    "                    trial_data_metadata = metadata\n",
    "                interval = pandas.read_table(mm, nrows=interval_count, delim_whitespace=True,\n",
    "                                             names=['Calls', 'Subcalls', 'Exclusive',\n",
    "                                                    'Inclusive', 'ProfileCalls', 'Group'],\n",
    "                                             engine='c')\n",
    "                split_index = interval.reset_index()['index'].apply(cls.extract_from_timer_name)\n",
    "                for n, col in enumerate(['Timer Name', 'Timer Location', 'Timer Type']):\n",
    "                    interval[col] = split_index.apply(lambda l: l[n]).values\n",
    "                mm.seek(0)\n",
    "                for i in range(0, interval_count + 2):\n",
    "                    mm.readline()\n",
    "                cls._parse_atomic_header(mm)\n",
    "                atomic = pandas.read_table(mm, names=['Count', 'Maximum', 'Minimum', 'Mean', 'SumSq'],\n",
    "                                           delim_whitespace=True, engine='c')\n",
    "                mm.close()\n",
    "                intervals.append(interval)\n",
    "                atomics.append(atomic)\n",
    "                indices.append((node, context, thread))\n",
    "                # print(atomic)\n",
    "\n",
    "        interval_df = pandas.concat(intervals, keys=indices)\n",
    "        interval_df.index.rename(['Node', 'Context', 'Thread', 'Timer'], inplace=True)\n",
    "        atomic_df = pandas.concat(atomics, keys=indices)\n",
    "        atomic_df.index.rename(['Node', 'Context', 'Thread', 'Timer'], inplace=True)\n",
    "        return cls(trial, trial_data_metric, trial_data_metadata, indices, interval_df, atomic_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
